<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Silvio  Amir


  | publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🤖</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://samiroid.github.io/">
       <span class="font-weight-bold">Silvio</span>   Amir
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
                    
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/students/">
                students
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/talks/">
                talks
                
              </a>
          </li>
          
                    
          <li class="nav-item ">
            <a class="nav-link" href="/assets/amircv21.pdf" target="_blank">
              cv              
              <span class="sr-only">(current)</span>              
            </a>
          </li>
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title aloha" style="font-weight: 500;">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">PACMHCI</abbr>
    
  
  </div>

  <div id="mueller2021demographic" class="col-sm-8">
    
      <div class="title">Demographic representation and collective storytelling in the me too twitter hashtag activism movement</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Mueller, Aaron,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wood-Doughty, Zach,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dredze, Mark,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Nobles, Alicia Lynn
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the ACM on Human-Computer Interaction</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2010.06472" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="https://dl.acm.org/doi/abs/10.1145/3449181" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mueller2021demographic.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The #MeToo movement on Twitter has drawn attention to the pervasive nature of sexual harassment and violence. While #MeToo has been praised for providing support for self-disclosures of harassment or violence and shifting societal response, it has also been criticized for exemplifying how women of color have been discounted for their historical contributions to and excluded from feminist movements. Through an analysis of over 600,000 tweets from over 256,000 unique users, we examine online #MeToo conversations across gender and racial/ethnic identities and the topics that each demographic emphasized. We found that tweets authored by white women were overrepresented in the movement compared to other demographics, aligning with criticism of unequal representation. We found that intersected identities contributed differing narratives to frame the movement, co-opted the movement to raise visibility in parallel ongoing movements, employed the same hashtags both critically and supportively, and revived and created new hashtags in response to pivotal moments. Notably, tweets authored by black women often expressed emotional support and were critical about differential treatment in the justice system and by police. In comparison, tweets authored by white women and men often highlighted sexual harassment and violence by public figures and weaved in more general political discussions. We discuss the implications of this work for digital activism research and design, including suggestions to raise visibility by those who were under-represented in this hashtag activism movement. Content warning: this article discusses issues of sexual harassment and violence.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NAACL</abbr>
    
  
  </div>

  <div id="amir2021impact" class="col-sm-8">
    
      <div class="title">On the Impact of Random Seeds on the Fairness of Clinical Classifiers</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meent, Jan-Willem,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Wallace, Byron C
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2104.06338" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="https://aclanthology.org/2021.naacl-main.299/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/amir2021impact.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent work has shown that fine-tuning large networks is surprisingly sensitive to changes in random seed(s). We explore the implications of this phenomenon for model fairness across demographic groups in clinical prediction tasks over electronic health records (EHR) in MIMIC-III —— the standard dataset in clinical NLP research. Apparent subgroup performance varies substantially for seeds that yield similar overall performance, although there is no evidence of a trade-off between overall and subgroup performance. However, we also find that the small sample sizes inherent to looking at intersections of minority groups and somewhat rare conditions limit our ability to accurately estimate disparities. Further, we find that jointly optimizing for high overall performance and low disparities does not yield statistically significant improvements. Our results suggest that fairness work using MIMIC-III should carefully account for variations in apparent differences that may arise from stochasticity and small sample sizes</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICWSM</abbr>
    
  
  </div>

  <div id="wadhwa2020aligning" class="col-sm-8">
    
      <div class="title">Aligning Public Feedback to Requests for Comments on Regulations.gov</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Wadhwa, Manya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dredze, Mark
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the International AAAI Conference on Web and Social Media</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/7369" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/wadhwa2020aligning.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In an effort to democratize the regulatory process, the United States Federal government created regulations.gov, a portal through which federal agencies can share proposed regulations and solicit feedback from the public. A proposed regulation will contain several requests for feedback on specific topics, and the public can then submit comments in response. While this reduces barriers to soliciting feedback, it still leaves regulators with a challenge: how to produce a summary and incorporate feedback from the sometimes tens of thousands of submitted comments. We propose an information retrieval system by which comments are aligned to specific regulatory requests. We evaluate several measures of semantic similarity for matching comments to information requests. We evaluate our proposed system over a dataset containing several regulations proposed for electronic cigarettes, an issue that energized tens of thousands of comments in response</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">PROPOR</abbr>
    
  
  </div>

  <div id="carvalho2020" class="col-sm-8">
    
      <div class="title">Situational Irony in Farcical News Headlines</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Carvalho, Paula,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Martins, Bruno,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Rosa, Hugo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Baptista, Jorge,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Mário J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Computational Processing of the Portuguese Language</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.springer.com/gp/book/9783030415044" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Current approaches to the computational modelling of irony mostly address verbal irony and sarcasm, neglecting other productive types of irony, namely situational irony. The function of situational irony is to lay emphasis on (real or fictional) events that evoke peculiar and unexpected images, which usually create a comical effect on the audience. In this paper, we investigate the linguistic and rhetorical devices underlying this phenomenon in a corpus composed of farcical news headlines, aiming at its automatic recognition. Based on a thorough annotation study, we found that in news headlines unexpectedness is mainly achieved by combining terms from different conceptual domains (what we have called out-of-domain contrast). We then explored features for automatically identifying these semantic and pragmatic incongruities and evaluated their discriminating power in a corpus whose irony is expressed by means of out-of-domain contrast. The features explored in our experiments are globally effective in capturing this phenomenon, attaining a six percent improvement in terms of the F-Measure over a baseline that only considers lexical information. Moreover, we observed that the best features typically reported in the literature for identifying incongruity in sarcastic text are not relevant for detecting situational irony in farcical news, thus reinforcing the idea that these phenomena pose different challenges that require distinct modelling approaches.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CLPsych</abbr>
    
  
  </div>

  <div id="amir2019mental" class="col-sm-8">
    
      <div class="title">Mental health surveillance over social media with digital cohorts</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dredze, Mark,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ayers, John W
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/amir2019mental.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The ability to track mental health conditions via social media opened the doors for large-scale, automated, mental health surveillance. However, inferring accurate population-level trends requires representative samples of the underlying population, which can be challenging given the biases inherent in social media data. While previous work has adjusted samples based on demographic estimates, the populations were selected based on specific outcomes, e.g. specific mental health conditions. We depart from these methods, by conducting analyses over demographically representative digital cohorts of social media users. To validate this approach, we constructed a cohort of US based Twitter users to measure the prevalence of depression and PTSD, and investigate how these illnesses manifest across demographic subpopulations. The analysis demonstrates that cohort-based studies can help control for sampling biases, contextualize outcomes, and provide deeper insights into the data</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">PhD Thesis</abbr>
    
  
  </div>

  <div id="amir2018" class="col-sm-8">
    
      <span id="amir2018">Amir, S. (2018). <i>Agile Social Media Analysis with Neural Networks</i>.</span>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/amir_thesis.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This thesis proposes an agile framework to accelerate the development of Social Media Analysis (SMA) systems by tackling some of the fundamental challenges of processing user generated content and the main limitations of current methodologies. The noise, brevity and ambiguity of social media pose challenges to traditional NLP methods, often forcing analysts to rely on sub-optimal methods or devote extensive manual efforts in the development of specialized models. On the other hand, social media users are not a representative sample of the population. Yet, current approaches tend to ignore the inherent biases of social media, and thus the outcomes of the analyses might not reflect broader trends. The proposed framework relies on a novel method to derive low-resource supervised neural networks in two steps: (i) learning unsupervised neural embeddings for words and users; (ii) constructing minimalist neural architectures that yield low-capacity models, which can be trained with scarce labeled data. By reducing the efforts of developing specialized models, the framework facilitates the deployment of more sophisticated SMA systems. In this work, it is used to implement methodologies to sample demographically representative digital cohorts of social media users. These cohorts can be leveraged to conduct demographically controlled studies, thereby mitigating sampling biases and allowing analysts to extrapolate findings gleaned from imperfect datasets and affording deeper insights. The evaluation of the framework was conducted over two case- studies, one involving the development of bespoke classifiers for social sciences studies, and the other concerned with the deployment of DEMOS, a novel digital epidemiology system to track public health discussions and monitor the prevalence of mental illnesses.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MLHC</abbr>
    
  
  </div>

  <div id="amir2017mlhc" class="col-sm-8">
    
      <div class="title">Quantifying Mental Health from Social Media with Neural User Embeddings</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Coppersmith, Glen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Carvalho, Paula,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Silva, Mario J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Wallace, Bryon C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2nd Machine Learning for Healthcare Conference</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://proceedings.mlr.press/v68/amir17a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/amir2017mlhc.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Mental illnesses adversely affect a significant proportion of the population worldwide. However, the typical methods to estimate and characterize the prevalence of mental health conditions are time-consuming and expensive. Consequently, best-available estimates concerning the prevalence of these conditions are often years out of date. Automated approaches that supplement traditional methods with broad, aggregated information derived from social media provide a potential means of furnishing near real-time estimates at scale. These may in turn provide grist for supporting, evaluating and iteratively improving public health programs and interventions. We propose a novel approach for mental health quantification that leverages user em-beddings induced from social media post histories. Recent work showed that learned user representations capture latent aspects of individuals (e.g., political leanings). This paper investigates whether these representations also correlate with mental health statuses. To this end, we induced embeddings for a set of users known to be affected by depression and post-traumatic stress disorder, and for a set of demographically matched ‘control’ users. We then evaluated the induced user representations with respect to: (i) their ability to capture homophilic relations with respect to mental health statuses; and (ii) their predictive performance in downstream mental health models. Our experimental results demonstrate that learned user embeddings capture relevant signals for mental health quantification. </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="amir2016expanding" class="col-sm-8">
    
      <div class="title">Expanding Subjective Lexicons for Social Media Mining with Embedding Subspaces</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Astudillo, Rámon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ling, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Carvalho, Paula C,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Mário J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1701.00145" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
      
      <a href="/assets/pdf/amir2016expanding.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent approaches for sentiment lexicon induction have capitalized on pre-trained word embeddings that capture latent semantic properties. However, embeddings obtained by optimizing performance of a given task (e.g. predicting contextual words) are sub-optimal for other applications. In this paper, we address this problem by exploiting task-specific representations, induced via embedding sub-space projection. This allows us to expand lexicons describing multiple semantic properties. For each property, our model jointly learns suitable representations and the concomitant predictor. Experiments conducted over multiple subjective lexicons, show that our model outperforms previous work and other baselines; even in low training data regimes. Furthermore, lexicon-based sentiment classifiers built on top of our lexicons outperform similar resources and yield performances comparable to those of supervised models</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SemEval</abbr>
    
  
  </div>

  <div id="amir2016inesc" class="col-sm-8">
    
      <div class="title">INESC-ID at SemEval-2016 Task 4-A: Reducing the Problem of Out-of-Embedding Words</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Astudillo, Ramón,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ling, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Silva, Mario J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Trancoso, Isabel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://aclweb.org/anthology/S16-1036" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/amir2016inesc.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the INESC-ID system for the 2016 edition of SemEval Twitter Sentiment Analysis shared task (subtask 4-A). The system was based on the Non-Linear Sub-space Embedding (NLSE) model developed for last year’s competition. This model trains a projection of pre-trained embeddings into a small subspace using the supervised data available. Despite its simplicity, the system attained performances comparable to the best systems of last edition with no need for feature engineering.
One limitation of this model was the assumption that a pre-trained embedding was available for every word. In this paper, we investigated different strategies to overcome this limitation by exploiting character-level embeddings and learning representations for out-of-embedding vocabulary words. The resulting approach outperforms our previous model by a relatively small margin, while still attaining
strong results and a consistent good performance across all the evaluation datasets.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CONLL</abbr>
    
  
  </div>

  <div id="amir2016modelling" class="col-sm-8">
    
      <div class="title">Modelling Context with User Embeddings for Sarcasm Detection in Social Media</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wallace, Byron C.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lyu, Hao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Carvalho, Paula,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Mario J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1607.00976" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="http://aclweb.org/anthology/K16-1017" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/amir2016modelling.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We introduce a deep neural network for automated sarcasm detection. Recent work has emphasized the need for models to capitalize on contextual features, beyond lexical and syntactic cues present in utterances. For example, different speakers will tend to employ sarcasm regarding different subjects and, thus, sarcasm detection models ought to encode such speaker information. Current methods have achieved this by way of laborious feature engineering. By contrast, we propose to automatically learn and then exploit user embeddings, to be used in concert with lexical signals to recognize sarcasm. Our approach does not require elaborate feature engineering (and concomitant data scraping); fitting user embeddings requires only the text from their previous posts. The experimental results show that our model outperforms a state-of-the-art approach leveraging an extensive set of carefully crafted features.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SemEval</abbr>
    
  
  </div>

  <div id="amir-EtAl-2015-SemEval" class="col-sm-8">
    
      <div class="title">INESC-ID: A Regression Model for Large Scale Twitter Sentiment Lexicon Induction</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ling, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Astudillo, Ramón,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Martins, Bruno,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Silva, Mario J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Trancoso, Isabel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://www.aclweb.org/anthology/S15-2102" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/amir-EtAl-2015-SemEval.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the approach followed by INESC-ID in the SemEval 2015 Twitter Sentiment
Analysis challenge, subtask E. The goal was to determine the strength of the association of
Twitter terms with positive sentiment. Using two labeled lexicons, we trained a regression
model to predict the sentiment polarity and intensity of words and phrases. Terms were represented as word embeddings induced in an unsupervised fashion from a corpus of tweets. Our system attained the top ranking submission, attesting the general adequacy of the proposed approach</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">EMNLP</abbr>
    
  
  </div>

  <div id="ling-EtAl-2015-EMNLP1" class="col-sm-8">
    
      <div class="title">Not All Contexts Are Created Equal: Better Word Representations with Variable Attention</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ling, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tsvetkov, Yulia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fermandez, Ramon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dyer, Chris,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Black, Alan W,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Trancoso, Isabel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lin, Chu-Cheng
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://aclweb.org/anthology/D15-1161" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/ling-EtAl-2015-EMNLP1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We introduce an extension to the bag-of-words model for learning words representations that take into account both syntactic and semantic properties within language. This is done by employing an attention model that finds within the contextual words, the words that are relevant for each prediction. The general intuition of our model is that some words are only relevant for predicting local context (e.g. function words), while other words are more suited for determining global con- text, such as the topic of the document. Experiments performed on both semantically and syntactically oriented tasks show gains using our model over the existing bag-of-words model. Furthermore, compared to other more sophisticated models, our model scales better as we increase the size of the context of the model.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">EMNLP</abbr>
    
  
  </div>

  <div id="ling-EtAl-2015-EMNLP2" class="col-sm-8">
    
      <div class="title">Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ling, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dyer, Chris,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Black, Alan W,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Trancoso, Isabel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fermandez, Ramon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Marujo, Luis,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Luis, Tiago
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1508.02096" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="http://aclweb.org/anthology/D15-1176" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/ling-EtAl-2015-EMNLP2.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We introduce a model for constructing vector representations of words by composing characters using bidirectional LSTMs. Relative to traditional word representation models that have independent vectors for each word type, our model requires only a single vector per character type and a fixed set of parameters for the compositional model. Despite the compactness of this model and, more importantly, the arbitrary nature of the form–function relationship in language, our “composed” word representations yield state-of-the-art results in language modeling and part-of-speech tagging. Benefits over traditional baselines are particularly pronounced in morphologically rich languages (e.g., Turkish).</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="saleiro2015popmine" class="col-sm-8">
    
      <div class="title">Popmine: Tracking political opinion on the web</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Saleiro, Pedro,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Silva, Mário,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Soares, Carlos
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1511.09101" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/7363273" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/saleiro-EtAl-2015-Tracking.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The automatic content analysis of mass media in the social sciences has become necessary and possible with the raise of social media and computational power. One particularly promising avenue of research concerns the use of opinion mining. We design and implement the POPmine system which is able to collect texts from web-based conventional media (news items in mainstream media sites) and social media (blogs and Twitter) and to process those texts, recognizing topics and political actors, analyzing relevant linguistic units, and generating indicators of both frequency of mention and polarity (positivity/negativity) of mentions to political actors across sources, types of sources, and across time.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SemEval</abbr>
    
  
  </div>

  <div id="astudillo-EtAl-2015-SemEval" class="col-sm-8">
    
      <div class="title">INESC-ID: Sentiment Analysis without Hand-Coded Features or Linguistic Resources using Embedding Subspaces</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Astudillo, Ramón,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ling, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Martins, Bruno,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Silva, Mario J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Trancoso, Isabel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://www.aclweb.org/anthology/S15-2109" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/astudillo-EtAl-2015-SemEval.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the INESC-ID system for the message polarity classification task of SemEval 2015. The proposed system does not make use of any hand-coded features or linguistic resources. It relies on projecting pre-trained structured skip-gram word embeddings into a small subspace. The word embeddings can be obtained from large amounts of Twitter data in unsupervised form. The sentiment analysis supervised training is thus reduced to finding the optimal projection which can be carried out efficiently despite the little data available. We analyze in detail the proposed approach and show that a competitive system can be attained with only a few configuration parameters</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ACL</abbr>
    
  
  </div>

  <div id="astudillo-EtAl-2015-ACL-IJCNLP" class="col-sm-8">
    
      <div class="title">Learning Word Representations from Scarce and Noisy Data with Embedding Subspaces</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Astudillo, Ramón,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ling, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Silva, Mario,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Trancoso, Isabel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://www.aclweb.org/anthology/P15-1104" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/astudillo-EtAl-2015-ACL-IJCNLP.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We investigate a technique to adapt unsupervised word embeddings to specific ap-
plications, when only small and noisy labeled datasets are available. Current methods use pre-trained embeddings to initialize model parameters, and then use the labeled data to tailor them for the intended
task. However, this approach is prone to overfitting when the training is performed with scarce and noisy data. To overcome this issue, we use the supervised data to find an embedding subspace that fits the task complexity. All the word representations are adapted through a projection into this task-specific subspace, even if they do not occur on the labeled dataset. This approach was recently used in the SemEval 2015 Twitter sentiment analysis challenge, attaining state-of-the-art results. Here we show results improving those of the challenge, as well as additional experiments in a Twitter Part-Of-Speech tagging task.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SemEval</abbr>
    
  
  </div>

  <div id="amir-EtAl-2014-SemEval" class="col-sm-8">
    
      <div class="title">TUGAS: Exploiting unlabelled data for Twitter sentiment analysis</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Amir, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Almeida, Miguel B.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Martins, Bruno,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Filgueiras, João,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Mário J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://www.aclweb.org/anthology/S14-2120" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/amir-EtAl-2014-SemEval.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper describes our participation in the message polarity classification task of
SemEval 2014. We focused on exploiting unlabeled data to improve accuracy, combining features leveraging word representations with other, more common features, based on word tokens or lexicons. We analyse the contribution of the different features, concluding that unlabeled data yields significant improvements.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Program</abbr>
    
  
  </div>

  <div id="moreira2013tracking" class="col-sm-8">
    
      <div class="title">Tracking politics with POWER</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Moreira, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Batista, David S,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Carvalho, Paula,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Couto, Francisco M,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Mario J
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Program</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.emerald.com/insight/content/doi/10.1108/00330331311313708/full/html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Purpose: POWER is an ontology of political processes and entities. It is designed for tracking politicians, political organizations and elections, both in mainstream and social media. The aim of this paper is to propose a data model to describe political agents and their relations over time.

Design/methodology/approach: The authors propose a data model to describe political agents (politicans, political instutions and political associations) and their relations over time. The model is formalized as an ontology using the RDF format and the population is performed in two steps. First, a bootstrap process loads data collected from authoritative sources. Then, the ontology is enriched with alternative media names extracted from the web.

Findings: The ontology is published as a public resource following the guidelines of linked data and semantic web standards can be accessed via SPARQL endpoint.

Originality/value: The authors have developed an ontology for the political domain tailored to aid in the tasks of named entity recognition and resolution. It represents the complexity and dynamic nature of relations between political agents (politicians, political associations and political institutions) over time.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CLEF</abbr>
    
  
  </div>

  <div id="filgueiras2013popstar" class="col-sm-8">
    
      <div class="title">POPSTAR at RepLab 2013: Polarity for reputation classification</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Filgueiras, Joao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <span class="aloha"><u>Amir, Silvio</u></span>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In CLEF 2013 Evaluation Labs and Workshop Online Working Notes</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/filgueiras2013popstar.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper describes our participation in the Polarity for Reputation classification task of RepLab 2013. Our system leveraged on a set of components previously developed for a Twitter message polarity classifier. Following a supervised approach, a Logistic Regression classifier is trained from annotated data. A refined language model is used to represent tweets in terms of a vocabulary consisting only of the most informative terms with word features weighted using a measure from the Information Retrieval field. To help reduce the sparseness of the feature vector, the model is enriched with another, more compact, representation of the words. Finally, we extract features to capture the use of informal and affective language. Our approach ranked in the top three for all the metrics, showing that the strategies for Twitter Sentiment Analysis are useful for the task of Polarity for Reputation classification.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2011</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CAiSE</abbr>
    
  
  </div>

  <div id="moreira2011power" class="col-sm-8">
    
      <div class="title">POWER - Politics Ontology for Web Entity Retrieval</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <span class="aloha"><u>Moreira, Silvio</u></span>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Batista, David,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Carvalho, Paula,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Couto, Francisco M.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Mário J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advanced Information Systems Engineering Workshops</em>
      
      
        2011
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/moreira2011power.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>POWER is an ontology of political processes. It is designed for tracking politicians, political organisations and elections, both in mainstream and social media. In social media, these entities (particularly humans) are frequently named by emergent abbreviations, non-standardized acronyms, nicknames, metaphoric expressions and neologisms. Politicians are also frequently mentioned in texts by their roles in the political scene, which may change rapidly over time. This paper describes how POWER was designed for tracking such complex and dynamic setting, with the purpose of making it a key resource to analytics applications mining the media</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Silvio  Amir.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.  

    
    
    Last updated: August 26, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
